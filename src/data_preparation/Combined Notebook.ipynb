{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import eurostat\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Education Attainment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karle\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# Import the data from Eurostat\n",
    "df = eurostat.get_data_df('edat_lfse_04')\n",
    "df.columns = df.columns.astype(str)\n",
    "\n",
    "# Drop all years before 2012 and columns unit and age (same for all entries)\n",
    "df = df.drop(df.loc[:, '2011': '2000'].columns, axis = 1)\n",
    "df = df.drop(['unit', 'age'], axis = 1)\n",
    "\n",
    "# Keep only total values and discard the gender column\n",
    "df = df[df.sex == 'T']\n",
    "df = df.drop('sex', axis = 1)\n",
    "\n",
    "# Rename to avoid problems using \\\n",
    "df = df.rename(columns={'geo\\\\time': ' NUTS 2'})\n",
    "\n",
    "# Merge on all entries which are also in the target variable cities to extract only the interesting cities\n",
    "target_cities = pd.read_csv(\"Cities_with_codes.csv\")\n",
    "education_attainment = pd.merge(target_cities, df, on=[' NUTS 2'])\n",
    "\n",
    "# Glasgow is missing all values except 2012\n",
    "Glasgow = education_attainment.loc[education_attainment['City'] == 'Glasgow']\n",
    "# Whole region of Scotland is UKM\n",
    "# Glasgow (Metro area) is approx 33% of the population it should be a reasonable approximation\n",
    "temp  = df[df[' NUTS 2'] == 'UKM']\n",
    "temp = temp.loc[:,'2019':'2013']\n",
    "Glasgow.loc[:, '2019':'2013'] = temp.loc[:, '2019':'2013'].to_numpy()\n",
    "education_attainment[education_attainment['City'] == 'Glasgow'] = Glasgow\n",
    "\n",
    "\n",
    "# Impute the missing values from 2012 using padding\n",
    "education_attainment.loc[:, '2019':'2012'] = education_attainment.loc[:, '2019':'2012'].fillna(method='pad',axis=1)\n",
    "\n",
    "# Split in to 3 separate tables depending on education level\n",
    "edu_ED_0_2 = education_attainment[education_attainment['isced11'] == 'ED0-2']\n",
    "edu_ED_3_4 = education_attainment[education_attainment['isced11'] == 'ED3_4']\n",
    "edu_ED_5_8 = education_attainment[education_attainment['isced11'] == 'ED5-8']\n",
    "\n",
    "#To be able to merge with the other data\n",
    "#Transform the columns of each year to a variable year\n",
    "yearly_data = dict()\n",
    "education_attainment  = pd.DataFrame()\n",
    "for year in range(2012,2020):\n",
    "    yearly_data= edu_ED_0_2[ list(edu_ED_0_2.loc[:,'City':' Country']) + [f\"{year}\"]]\n",
    "    yearly_data.insert(4, \"Year\", year)\n",
    "    yearly_data = yearly_data.rename(columns={f\"{year}\": \"Education Attainment ED 0-2\"})\n",
    "    yearly_data.insert(6, \"Education Attainment ED 3-4\", edu_ED_3_4[f\"{year}\"].to_numpy())\n",
    "    yearly_data.insert(7, \"Education Attainment ED 5-8\", edu_ED_5_8[f\"{year}\"].to_numpy())\n",
    "    education_attainment = education_attainment.append(yearly_data)\n",
    "    \n",
    "education_attainment = education_attainment.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Victims in Road Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing cities:  ['Belgrade' 'Edinburgh' 'Glasgow' 'Reykjavik']\n"
     ]
    }
   ],
   "source": [
    "# Get the data from Eurostat\n",
    "df = eurostat.get_data_df('tran_r_acci')\n",
    "df.columns = df.columns.astype(str)\n",
    "# Drop all years before 2012, keep only with unit measure Per Million Inhabitants and accident type deadly\n",
    "df = df.drop(df.loc[:, '2011': ].columns, axis = 1)\n",
    "df = df[df.unit == 'P_MHAB']\n",
    "df = df[df.victim == 'KIL']\n",
    "\n",
    "# Rename to avoid problems using \\\n",
    "df = df.rename(columns={'geo\\\\time': ' NUTS 2'})\n",
    "\n",
    "# Insert missing cloumn for 2019\n",
    "df.insert(3,\"2019\",np.NaN)\n",
    "\n",
    "# Merge on all entries which are also in the target variable cities to extract only the interesting cities\n",
    "target_cities = pd.read_csv(\"Cities_with_codes.csv\")\n",
    "road_accidents = pd.merge(target_cities, df, on=[' NUTS 2'])\n",
    "\n",
    "# Check for missing cities\n",
    "missing_cities = target_cities[-target_cities[' NUTS 2'].isin(road_accidents[' NUTS 2'])]\n",
    "\n",
    "\n",
    "print(\"Missing cities: \", missing_cities.values[:,0])\n",
    "\n",
    "# Data from Icelandic ministry of transportation\n",
    "#https://www.samgongustofa.is/umferd/tolfraedi/slysatolur/arsskyrslur-slysaskraningar/\n",
    "# Reported as deaths per 10,000\n",
    "Reykjavik  = [0.0, 30.0, 20.0, 10.0, 20.0, 0.0, 10.0, 10.0]\n",
    "Reykjavik = ['Reykjavik', 'IS001C1','IS00','IS','KIL','P_MHAB']+Reykjavik\n",
    "road_accidents.loc[77] = Reykjavik\n",
    "\n",
    "# Table 1-1 in : https://www.abs.gov.rs/admin/upload/documents/20181016102533-statistical_report_2016_english.pdf\n",
    "# 20% of the population is in Belgrade so we take 20% of the accidents as occuring there\n",
    "# and divide by 1.7 (million inhabitants)\n",
    "Belgrade = [np.NaN, np.NaN,np.NaN, 619, 594, 476, 548, 551]\n",
    "Belgrade = np.multiply(Belgrade,(0.2/1.7))\n",
    "Belgrade = np.around(Belgrade, 1)\n",
    "Belgrade = ['Belgrade', '-','RS11','RS','KIL','P_MHAB']+Belgrade.tolist()\n",
    "road_accidents.loc[78] = Belgrade\n",
    "\n",
    "# Traffic death data from Scotland\n",
    "# https://statistics.gov.scot/data/road-safety\n",
    "# Select by region\n",
    "\n",
    "# Divide by 0.5 (million inhabitants)\n",
    "Edinburgh = [np.NaN, 5, 6, 9, 3, 11, 8, 13]\n",
    "Edinburgh = np.divide(Edinburgh,0.5)\n",
    "Edinburgh = np.around(Edinburgh, 1)\n",
    "Edinburgh = ['Edinburgh', 'UK007C1','UKM7','UK','KIL','P_MHAB']+Edinburgh.tolist()\n",
    "road_accidents.loc[79] = Edinburgh\n",
    "\n",
    "# Divide by 0.6 (million inhabitants)\n",
    "Glasgow = [np.NaN, 10, 7, 8, 15, 18, 4, 7]\n",
    "Glasgow = np.divide(Glasgow,0.6)\n",
    "Glasgow = np.around(Glasgow, 1)\n",
    "Glasgow = ['Glasgow', 'UK004C1','UKM3','UK','KIL','P_MHAB']+Glasgow.tolist()\n",
    "road_accidents.loc[80] = Glasgow\n",
    "\n",
    "# Impute using padding to fill missing values\n",
    "road_accidents.loc[:, '2019':'2013'] = road_accidents.loc[:, '2019':'2012'].fillna(method='backfill',axis=1)\n",
    "road_accidents.loc[:, '2019':'2012'] = road_accidents.loc[:, '2019':'2012'].fillna(method='ffill',axis=1)\n",
    "\n",
    "#To be able to merge with the other data\n",
    "#Transform the columns of each year to a variable year\n",
    "yearly_data = dict()\n",
    "deaths_in_road_accidents  = pd.DataFrame()\n",
    "for year in range(2012,2020):\n",
    "    yearly_data= road_accidents[ list(road_accidents.loc[:,'City':' Country']) + [f\"{year}\"]]\n",
    "    yearly_data.insert(4, \"Year\", year)\n",
    "    yearly_data = yearly_data.rename(columns={f\"{year}\": \"Deaths_in_road_accidents\"})\n",
    "    deaths_in_road_accidents = deaths_in_road_accidents.append(yearly_data)\n",
    "deaths_in_road_accidents = deaths_in_road_accidents.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Working Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasheet from eurostat\n",
    "df = eurostat.get_data_df('lfst_r_lfe2ehour')\n",
    "\n",
    "# Drop all years before 2012 and columns unit and age (same for all entries)\n",
    "df.columns = df.columns.astype(str)\n",
    "df = df.drop(df.loc[:, '2011': ].columns, axis = 1)\n",
    "# Rename to avoid problems using \\\n",
    "df = df.rename(columns={'geo\\\\time': ' NUTS 2'})\n",
    "\n",
    "# Extract the data for both sexes (Total) and age group 15-74\n",
    "df = df[df.sex == 'T']\n",
    "df = df.drop('sex', axis = 1)\n",
    "df = df[df.age == 'Y15-74']\n",
    "\n",
    "# Merge on all entries which are also in the target variable cities to extract only the interesting cities\n",
    "target_cities = pd.read_csv(\"Cities_with_codes.csv\")\n",
    "avg_hours = pd.merge(target_cities, df, on=[' NUTS 2'])\n",
    "\n",
    "# Glasgow is missing all values except 2012\n",
    "Glasgow = avg_hours.loc[avg_hours['City'] == 'Glasgow']\n",
    "# Whole region of Scotland is UKM\n",
    "# Glasgow is 40% of the population it should be a reasonable approximation\n",
    "temp  = df[df[' NUTS 2'] == 'UKM']\n",
    "temp = temp.loc[:,'2019':'2013']\n",
    "Glasgow.loc[:, '2019':'2013'] = temp.loc[:, '2019':'2013'].to_numpy()\n",
    "avg_hours[avg_hours['City'] == 'Glasgow'] = Glasgow\n",
    "\n",
    "# Impute the rest using padding\n",
    "avg_hours.loc[:, '2019':'2012'] = avg_hours.loc[:, '2019':'2012'].fillna(method='pad',axis=1)\n",
    "\n",
    "#To be able to merge with the other data\n",
    "#Transform the columns of each year to a variable year\n",
    "yearly_data = dict()\n",
    "avg_working_hours  = pd.DataFrame()\n",
    "for year in range(2012,2020):\n",
    "    yearly_data= avg_hours[ list(avg_hours.loc[:,'City':' Country']) + [f\"{year}\"]]\n",
    "    yearly_data.insert(4, \"Year\", year)\n",
    "    yearly_data = yearly_data.rename(columns={f\"{year}\": \"Average Working Hours\"})\n",
    "    avg_working_hours = avg_working_hours.append(yearly_data)\n",
    "avg_working_hours = avg_working_hours.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unemployment Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the datasheet from Eurostat\n",
    "df = eurostat.get_data_df('lfst_r_lfu3rt')\n",
    "\n",
    "# Drop all years before 2012 and columns unit and age (same for all entries)\n",
    "df.columns = df.columns.astype(str)\n",
    "df = df.drop(df.loc[:, '2011': ].columns, axis = 1)\n",
    "# Rename to avoid problems using \\\n",
    "df = df.rename(columns={'geo\\\\time': ' NUTS 2'})\n",
    "\n",
    "# Extract the data for both sexes (Total) and age group 15-74\n",
    "df = df[df.sex == 'T']\n",
    "df = df[df.age == 'Y15-74']\n",
    "df = df.drop(['sex','unit','age'], axis = 1)\n",
    "\n",
    "# Merge on all entries which are also in the target variable cities to extract only the interesting cities\n",
    "target_cities = pd.read_csv(\"Cities_with_codes.csv\")\n",
    "unemployment_rate = pd.merge(target_cities, df, on=[' NUTS 2'])\n",
    "\n",
    "# Glasgow is missing all values except 2012\n",
    "Glasgow = unemployment_rate.loc[unemployment_rate['City'] == 'Glasgow']\n",
    "# Whole region of Scotland is UKM\n",
    "# Glasgow is 40% of the population it should be a reasonable approximation\n",
    "temp  = df[df[' NUTS 2'] == 'UKM']\n",
    "temp = temp.loc[:,'2019':'2013']\n",
    "Glasgow.loc[:, '2019':'2013'] = temp.loc[:, '2019':'2013'].to_numpy()\n",
    "unemployment_rate[unemployment_rate['City'] == 'Glasgow'] = Glasgow\n",
    "\n",
    "# Impute the rest using padding\n",
    "unemployment_rate.loc[:, '2019':'2012'] = unemployment_rate.loc[:, '2019':'2012'].fillna(method='pad',axis=1)\n",
    "\n",
    "#To be able to merge with the other data\n",
    "#Transform the columns of each year to a variable year\n",
    "yearly_data = dict()\n",
    "unemployment_rate_data  = pd.DataFrame()\n",
    "for year in range(2012,2020):\n",
    "    yearly_data= unemployment_rate[ list(unemployment_rate.loc[:,'City':' Country']) + [f\"{year}\"]]\n",
    "    yearly_data.insert(4, \"Year\", year)\n",
    "    yearly_data = yearly_data.rename(columns={f\"{year}\": \"Unemployment_Rate\"})\n",
    "    unemployment_rate_data = unemployment_rate_data.append(yearly_data)\n",
    "unemployment_rate_data = unemployment_rate_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code if we want to do it with csv files, requires all in the same format and not other existing csv files in the folder\n",
    "\n",
    "#initial = pd.read_csv('Education_Attainment.csv')\n",
    "#merged = initial\n",
    "#\n",
    "#for file_name in glob.glob('*.csv'):\n",
    "#    if file_name == 'Education_Attainment.csv':\n",
    "#        continue \n",
    "#    temp_dataframe = pd.read_csv(file_name)\n",
    "#    values = temp_dataframe.drop(columns=[' City Code', ' NUTS 2',' Country'])\n",
    "#    merged = merged.merge(values, on=['City', 'Year'])\n",
    "\n",
    "\n",
    "# Code to do it directly in the notebook without saving to csv files first\n",
    "# Right now requires all data to be complete\n",
    "data_sheets = [deaths_in_road_accidents,avg_working_hours,unemployment_rate_data]\n",
    "\n",
    "initial = education_attainment\n",
    "merged = initial\n",
    "\n",
    "for file_name in data_sheets:\n",
    "    temp_dataframe = file_name\n",
    "    values = temp_dataframe.drop(columns=[' City Code', ' NUTS 2',' Country'])\n",
    "    merged = merged.merge(values, on=['City', 'Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has NaN values:  False\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}